#!/usr/bin/env python3
import logging
import datetime


from PIL import Image
from pytesseract import image_to_string
from bs4 import BeautifulSoup
from urllib.request import urlopen, Request
from io import BytesIO
import re

# The arrow library is used to handle datetimes
import arrow
# The request library is used to fetch content through HTTP
import requests
from .JP import fetch_production as JP_fetch_production

# please try to write PEP8 compliant code (use a linter). One of PEP8's
# requirement is to limit your line length to 79 characters.


def fetch_production(zone_key='JP-KN', session=None,
                     target_datetime: datetime.datetime = None,
                     logger: logging.Logger = logging.getLogger(__name__)):

    """
    This method adds nuclear production on top of the solar data returned by the JP parser.
    It tries to match the solar data with the nuclear data.
    If there is a difference of more than 30 minutes between solar and nuclear data, the method will fail.
    """
    r = session or requests.session()
    if target_datetime is not None:
         raise NotImplementedError('This parser can only fetch live data')
    
    JP_data = JP_fetch_production(zone_key, session, target_datetime, logger)
    nuclear_mw, nuclear_datetime = get_nuclear_production()
    latest = JP_data[-1] #latest solar data is the most likely to fit with nuclear production
    diff = None
    if nuclear_datetime > latest["datetime"]:
        diff = nuclear_datetime-latest["datetime"]
    else:
        diff = latest["datetime"]-nuclear_datetime
    if abs(diff.seconds) > 30 * 60:
        raise Exception("Difference between nuclear datetime and JP data is too large")

    latest["production"]["nuclear"] = nuclear_mw
    latest["production"]["unknown"] = latest["production"]["unknown"] - nuclear_mw
    return latest

URL = "https://www.kepco.co.jp/energy_supply/energy/nuclear_power/info/monitor/live_unten"
IMAGE_CORE_URL = "https://www.kepco.co.jp/"

def getImageText(imgUrl, lang):
    """
    Fetches image based on URL, crops it and extract text from the image.
    """
    req = Request(imgUrl, headers={'User-Agent': 'Mozilla/5.0'})
    img_bytes = urlopen(req).read()
    img = Image.open(BytesIO(img_bytes))
    width, height = img.size
    img = img.crop((0, (height / 8), 160, height))
    # cropping the image, makes it easier to read for tesseract
    text = image_to_string(img, lang=lang)
    return text

def extractCapacity(tr):
    """
    The capacity for each unit has the class "list03".
    and it uses the chinese symbol for 10k(万).
    If this changes, the method will become inaccurate.
    """
    td = tr.findAll("td", {"class":"list03"})
    if len(td) == 0:
        return None
    raw_text = td[0].getText()
    kw_energy = raw_text.split("万")[0]   
    return float(kw_energy) * 10000

def extractOperationPercentage(tr):
    """Operation percentage is located on images of type .gif"""
    td = tr.findAll("img")
    if len(td) == 0:
        return None
    img = td[0]
    URL = IMAGE_CORE_URL + img["src"]
    if ".gif" in URL:
        text = getImageText(URL, "eng")
        # will return a number and percentage eg ("104%"). Sometimes a little more eg: ("104% 4...")
        split = text.split("%")
        if len(split) == 0:
            return None
        return float(split[0]) / 100
    else:
        return None

def extractTime(soup):
    """
    Time is located in an image.
    Decipher the text containing the data and assumes there will only be 4 digits making up the datetime.
    """
    imgRelative = soup.findAll("img", {"class": "time-data"})[0]["src"]
    imgUrlFull = IMAGE_CORE_URL + imgRelative 
    text = getImageText(imgUrlFull, "jpn")
    digits = re.findall(r'\d+', text)
    digits = list(map(lambda x: int(x), digits))
    if len(digits) != 4:
        # something went wrong while extracting time from Japan
        raise Exception("Something went wrong while extracting local time")
    nuclear_datetime = arrow.now(tz="Asia/Tokyo").replace(month=digits[0], day=digits[1], hour=digits[2], minute=digits[3]).floor("minute").datetime
    return nuclear_datetime

def get_nuclear_production():
    """
    Fetches all the rows that contains data of nuclear units and calculates the total kw generated by all plants.
    Illogically, all the rows has the class "mihama_realtime" which they might fix in the future.
    """
    r = Request(URL, headers={'User-Agent': 'Mozilla/5.0'})
    html = urlopen(r).read()
    soup = BeautifulSoup(html, 'html.parser')
    nuclear_datetime = extractTime(soup)
    rows = soup.findAll("tr", {"class": "mihama_realtime"})
    tr_list = soup.findAll("tr")
    total_kw = 0
    for tr in tr_list:
        capacity = extractCapacity(tr)
        operation_percentage = extractOperationPercentage(tr)
        if (capacity == None or operation_percentage == None):
            continue
        kw = capacity * operation_percentage
        total_kw = total_kw + kw
    nuclear_mw = total_kw / 1000.0 # convert to mw
    return (nuclear_mw, nuclear_datetime)



if __name__ == '__main__':
    """Main method, never used by the Electricity Map backend, but handy for testing."""

    print('fetch_production() ->')
    print(fetch_production())
